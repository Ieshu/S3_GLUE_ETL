{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf60853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "It looks like there is a newer version of the kernel available. The latest version is 1.0.4 and you have 1.0.1 installed.\n",
      "Please run `pip install --upgrade aws-glue-sessions` to upgrade your kernel\n",
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::935670829844:role/dwhR.\n",
      "Setting Glue version to: 3.0\n",
      "Previous region: us-east-1\n",
      "Setting new region to: us-east-1\n",
      "Region is set to: us-east-1\n",
      "Trying to create a Glue session for the kernel.\n",
      "Session Type: etl\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 5\n",
      "Session ID: 1b3c82ee-ca2c-4b76-ab62-b0e520af0a1d\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 1.0.1\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session 1b3c82ee-ca2c-4b76-ab62-b0e520af0a1d to get into ready status...\n",
      "Session 1b3c82ee-ca2c-4b76-ab62-b0e520af0a1d has been created.\n",
      "Ready to develop\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::935670829844:role/dwhR\n",
    "%glue_version 3.0\n",
    "%region us-east-1\n",
    "print(\"Ready to develop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be580cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.sql.functions import col, expr\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "import sys\n",
    "\n",
    "args = getResolvedOptions(sys.argv, [\"JOB_NAME\"])\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args[\"JOB_NAME\"], args)\n",
    "\n",
    "# Script generated for node Amazon S3\n",
    "AmazonS3_node1702362906597 = glueContext.create_dynamic_frame.from_catalog(\n",
    "    database=\"people_db1\",\n",
    "    table_name=\"input_large_csv\",\n",
    "    transformation_ctx=\"AmazonS3_node1702362906597\",\n",
    ")\n",
    "\n",
    "# Print the schema of the DynamicFrame\n",
    "print(\"Schema of AmazonS3_node1702362906597:\")\n",
    "print(AmazonS3_node1702362906597.printSchema())\n",
    "\n",
    "# Transformation 1: Filter records where age is greater than 25\n",
    "transformed_data_1 = Filter.apply(frame=AmazonS3_node1702362906597, f=lambda x: x[\"age\"] > 25)\n",
    "\n",
    "# Transformation: Add a new column 'city_category' based on city\n",
    "transformed_data_1 = transformed_data_1.toDF()\n",
    "transformed_data = transformed_data_1.withColumn(\n",
    "    \"city_category\",\n",
    "    expr(\"CASE WHEN city IN ('London', 'Paris') THEN 'Europe' ELSE 'Other' END\")\n",
    ")\n",
    "\n",
    "# Convert back to DynamicFrame\n",
    "transformed_dynamic_frame = DynamicFrame.fromDF(transformed_data, glueContext, \"transformed_data\")\n",
    "\n",
    "\n",
    "# Write the final transformed data to an S3 location in CSV format\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame=transformed_dynamic_frame,\n",
    "    connection_type=\"s3\",\n",
    "    connection_options={\"path\": \"s3://ieshaan-bucket-latest/output_data/\"},\n",
    "    format=\"csv\",\n",
    "    format_options={\"compression\": \"SNAPPY\", \"writeHeader\": True}  # Ensure writeHeader is set to True\n",
    ")\n",
    "\n",
    "job.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
